einops==0.8.0
fastapi==0.115.0
llama-cpp-python
# flash_attn==2.6.3
loguru==0.7.2
packaging==24.1
# Pillow==9.0.1
Pillow==10.4.0
pydantic==2.9.2
python-dotenv==1.0.1
Requests==2.32.3
streamlit==1.38.0
torch==2.4.0
torchvision==0.19.0
transformers==4.44.2
uvicorn==0.30.6
